{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built on Python 3.6.8\n",
    "import numpy as np #numpy version 1.16.3\n",
    "import tensorflow as tf #tensorflow-gpu version 1.13.1\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "train_images = np.load('./cifar-10-npy/train_data.npy')\n",
    "train_labels = np.load('./cifar-10-npy/train_labels_1hot.npy')\n",
    "test_images = np.load('./cifar-10-npy/test_data.npy')\n",
    "test_labels = np.load('./cifar-10-npy/test_labels_1hot.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing as described in 0-center data_l channel in CAFFE\n",
    "train_images = train_images - 50\n",
    "test_images = test_images - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce Size of Data Set to Prevent Memory Overflow and Speed Up Training\n",
    "no_of_labels = int(train_labels.max() + 1)\n",
    "\n",
    "train_images = np.reshape(train_images, newshape=(len(train_images),len(train_images[0]),len(train_images[0][0]),1))\n",
    "train_labels = np.reshape(train_labels, newshape=(len(train_images),len(train_images[0]),len(train_images[0][0]),1))\n",
    "\n",
    "train_images = train_images[0:200]\n",
    "train_labels = train_labels[0:200]\n",
    "\n",
    "test_images = np.reshape(test_images, newshape=(len(test_images),len(test_images[0]),len(test_images[0][0]),1))\n",
    "test_labels = np.reshape(test_labels, newshape=(len(test_images),len(test_images[0]),len(test_images[0][0]),1))\n",
    "\n",
    "test_images = test_images[0:40]\n",
    "test_labels = test_labels[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hara kumar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = keras.Sequential([\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(64, 3, padding='same', input_shape=(32, 32, 1), activation=tf.nn.relu), #bw_conv1_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu, strides=2), #conv1_2\\n    keras.layers.BatchNormalization(), #conv1_2norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu), #conv2_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu, strides=2), #conv2_2\\n    keras.layers.BatchNormalization(), #conv2_2norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_2\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=2), #conv3_3\\n    keras.layers.BatchNormalization(), #conv3_3norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_2\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_3\\n    keras.layers.BatchNormalization(), #conv4_3norm\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_1\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_2\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_3\\n    keras.layers.BatchNormalization(), #conv5_3norm\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_1\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_2\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_3\\n    keras.layers.BatchNormalization(), #conv6_3norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_2\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_3\\n    keras.layers.BatchNormalization(), #conv7_3norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2DTranspose(256, 4, padding='same', activation=tf.nn.relu, strides=2, dilation_rate=1), #conv8_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_2\\n    #keras.layers.ZeroPadding2D(padding=1),\\n    #keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_3\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=3, dilation_rate=1), #modified conv8_3\\n    keras.layers.Conv2D(no_of_labels, 1, padding='same', strides=1, dilation_rate=1) #convolve to labels\\n])\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, 3, padding='same', input_shape=(32, 32, 1), activation=tf.nn.relu), #bw_conv1_1\n",
    "    keras.layers.BatchNormalization(), #conv1_2norm\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_3\n",
    "    keras.layers.Conv2D(no_of_labels, 1, padding='same', strides=1, dilation_rate=1), #convolve to labels\n",
    "])\n",
    "\n",
    "'''\n",
    "model = keras.Sequential([\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(64, 3, padding='same', input_shape=(32, 32, 1), activation=tf.nn.relu), #bw_conv1_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu, strides=2), #conv1_2\n",
    "    keras.layers.BatchNormalization(), #conv1_2norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu), #conv2_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu, strides=2), #conv2_2\n",
    "    keras.layers.BatchNormalization(), #conv2_2norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_2\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=2), #conv3_3\n",
    "    keras.layers.BatchNormalization(), #conv3_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_2\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_3\n",
    "    keras.layers.BatchNormalization(), #conv4_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_1\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_2\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_3\n",
    "    keras.layers.BatchNormalization(), #conv5_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_1\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_2\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_3\n",
    "    keras.layers.BatchNormalization(), #conv6_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_2\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_3\n",
    "    keras.layers.BatchNormalization(), #conv7_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2DTranspose(256, 4, padding='same', activation=tf.nn.relu, strides=2, dilation_rate=1), #conv8_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_2\n",
    "    #keras.layers.ZeroPadding2D(padding=1),\n",
    "    #keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_3\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=3, dilation_rate=1), #modified conv8_3\n",
    "    keras.layers.Conv2D(no_of_labels, 1, padding='same', strides=1, dilation_rate=1) #convolve to labels\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch # 1\n",
      "WARNING:tensorflow:From c:\\users\\hara kumar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Finished epoch # 1\n",
      "Starting epoch # 2\n",
      "Finished epoch # 2\n",
      "Starting epoch # 3\n",
      "Finished epoch # 3\n",
      "Starting epoch # 4\n",
      "Finished epoch # 4\n",
      "Starting epoch # 5\n",
      "Finished epoch # 5\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 5 #HYPERPARAMETER\n",
    "for e in range (0, no_of_epochs):\n",
    "    print(\"Starting epoch #\", e+1)\n",
    "    for n in range(0, len(train_labels)):\n",
    "        train_images_n = np.reshape(train_images[n], newshape=(1,len(train_images[n]),len(train_images[n][0]),1))\n",
    "        train_labels_q = np.zeros((1,len(train_images[n]),len(train_images[n][0]),no_of_labels))\n",
    "        for i in range(0, len(train_labels[n])):\n",
    "            for j in range(0, len(train_labels[n][0])):\n",
    "                label = train_labels[0][i][j][0]\n",
    "                train_labels_q[0][i][j][int(label)] = 1\n",
    "        model.fit(train_images_n, train_labels_q, epochs=1, batch_size=1, verbose=0)\n",
    "    print(\"Finished epoch #\", e+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 11ms/sample - loss: 2.7805 - acc: 0.9901\n",
      "Test accuracy: 0.99009246\n"
     ]
    }
   ],
   "source": [
    "test_labels_q = np.zeros((len(test_images),len(test_images[0]),len(test_images[0][0]),no_of_labels))\n",
    "\n",
    "for n in range(0, len(test_labels)):\n",
    "    for i in range(0, len(test_labels[0])):\n",
    "        for j in range(0, len(test_labels[0][0])):\n",
    "            label = test_labels[n][i][j][0]\n",
    "            test_labels_q[n][i][j][int(label)] = 1\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels_q)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_images)\n",
    "prediction = np.reshape(prediction, newshape=(40,32,32,no_of_labels))\n",
    "prediction = prediction.argmax(axis=3)\n",
    "prediction = np.reshape(prediction, newshape=(40,32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./cifar-10-npy/test_labels_predictions', prediction)\n",
    "np.save('./cifar-10-npy/test_data_predictions', test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
