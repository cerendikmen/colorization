{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built on Python 3.6.8\n",
    "import numpy as np #numpy version 1.16.3\n",
    "import tensorflow as tf #tensorflow-gpu version 1.13.1\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "train_images = np.load('./cifar-10-npy/train_data.npy')\n",
    "train_labels = np.load('./cifar-10-npy/train_labels_1hot.npy')\n",
    "test_images = np.load('./cifar-10-npy/test_data.npy')\n",
    "test_labels = np.load('./cifar-10-npy/test_labels_1hot.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing as described in 0-center data_l channel in CAFFE\n",
    "train_images = train_images - 50\n",
    "test_images = test_images - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce Size of Data Set to Prevent Memory Overflow and Speed Up Training\n",
    "no_of_labels = int(train_labels.max() + 1)\n",
    "\n",
    "train_images = np.reshape(train_images, newshape=(len(train_images),len(train_images[0]),len(train_images[0][0]),1))\n",
    "train_labels = np.reshape(train_labels, newshape=(len(train_images),len(train_images[0]),len(train_images[0][0]),1))\n",
    "\n",
    "train_images = train_images[0:200]\n",
    "train_labels = train_labels[0:200]\n",
    "\n",
    "test_images = np.reshape(test_images, newshape=(len(test_images),len(test_images[0]),len(test_images[0][0]),1))\n",
    "test_labels = np.reshape(test_labels, newshape=(len(test_images),len(test_images[0]),len(test_images[0][0]),1))\n",
    "\n",
    "test_images = test_images[0:40]\n",
    "test_labels = test_labels[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hara kumar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = keras.Sequential([\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(64, 3, padding='same', input_shape=(32, 32, 1), activation=tf.nn.relu), #bw_conv1_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu, strides=2), #conv1_2\\n    keras.layers.BatchNormalization(), #conv1_2norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu), #conv2_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu, strides=2), #conv2_2\\n    keras.layers.BatchNormalization(), #conv2_2norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_2\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=2), #conv3_3\\n    keras.layers.BatchNormalization(), #conv3_3norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_2\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_3\\n    keras.layers.BatchNormalization(), #conv4_3norm\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_1\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_2\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_3\\n    keras.layers.BatchNormalization(), #conv5_3norm\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_1\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_2\\n    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_3\\n    keras.layers.BatchNormalization(), #conv6_3norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_2\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_3\\n    keras.layers.BatchNormalization(), #conv7_3norm\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2DTranspose(256, 4, padding='same', activation=tf.nn.relu, strides=2, dilation_rate=1), #conv8_1\\n    keras.layers.ZeroPadding2D(padding=1),\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_2\\n    #keras.layers.ZeroPadding2D(padding=1),\\n    #keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_3\\n    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=3, dilation_rate=1), #modified conv8_3\\n    keras.layers.Conv2D(no_of_labels, 1, padding='same', strides=1, dilation_rate=1) #convolve to labels\\n])\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, 3, padding='same', input_shape=(32, 32, 1), activation=tf.nn.relu), #bw_conv1_1\n",
    "    keras.layers.BatchNormalization(), #conv1_2norm\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_3\n",
    "    keras.layers.Conv2D(no_of_labels, 1, padding='same', strides=1, dilation_rate=1), #convolve to labels\n",
    "])\n",
    "\n",
    "'''\n",
    "model = keras.Sequential([\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(64, 3, padding='same', input_shape=(32, 32, 1), activation=tf.nn.relu), #bw_conv1_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu, strides=2), #conv1_2\n",
    "    keras.layers.BatchNormalization(), #conv1_2norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu), #conv2_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(128, 3, padding='same', activation=tf.nn.relu, strides=2), #conv2_2\n",
    "    keras.layers.BatchNormalization(), #conv2_2norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu), #conv3_2\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=2), #conv3_3\n",
    "    keras.layers.BatchNormalization(), #conv3_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_2\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv4_3\n",
    "    keras.layers.BatchNormalization(), #conv4_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_1\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_2\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv5_3\n",
    "    keras.layers.BatchNormalization(), #conv5_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_1\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_2\n",
    "    keras.layers.ZeroPadding2D(padding=2),#need padding of 2\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=2), #conv6_3\n",
    "    keras.layers.BatchNormalization(), #conv6_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_2\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(512, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv7_3\n",
    "    keras.layers.BatchNormalization(), #conv7_3norm\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2DTranspose(256, 4, padding='same', activation=tf.nn.relu, strides=2, dilation_rate=1), #conv8_1\n",
    "    keras.layers.ZeroPadding2D(padding=1),\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_2\n",
    "    #keras.layers.ZeroPadding2D(padding=1),\n",
    "    #keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=1, dilation_rate=1), #conv8_3\n",
    "    keras.layers.Conv2D(256, 3, padding='same', activation=tf.nn.relu, strides=3, dilation_rate=1), #modified conv8_3\n",
    "    keras.layers.Conv2D(no_of_labels, 1, padding='same', strides=1, dilation_rate=1) #convolve to labels\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0348 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0360 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0309 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0400 - acc: 0.9939\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0349 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0429 - acc: 0.9934\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 0.0351 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0371 - acc: 0.9943\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0346 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0389 - acc: 0.9943\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0549 - acc: 0.9917\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0315 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0302 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 0.0309 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0476 - acc: 0.9921\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0390 - acc: 0.9936\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 0.0361 - acc: 0.9938\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0331 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0314 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0335 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0399 - acc: 0.9943\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 0.0327 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0482 - acc: 0.9922\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0416 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0481 - acc: 0.9927\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0320 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0324 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0740 - acc: 0.9886\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0347 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0303 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0450 - acc: 0.9921\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0296 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0397 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0299 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0321 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0343 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0340 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0496 - acc: 0.9922\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0306 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0370 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0292 - acc: 0.9957\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0392 - acc: 0.9939\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0371 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0336 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0379 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0345 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0314 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0453 - acc: 0.9933\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0393 - acc: 0.9940\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0345 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0395 - acc: 0.9936\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0366 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0354 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0321 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0414 - acc: 0.9929\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0311 - acc: 0.9954\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0291 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0366 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0382 - acc: 0.9940\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0338 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0332 - acc: 0.9956\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0372 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0294 - acc: 0.9957\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0318 - acc: 0.9957\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0337 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0341 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0358 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0275 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0368 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0310 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0347 - acc: 0.9939\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0367 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0278 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0362 - acc: 0.9940\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0328 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0336 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0340 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0332 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0341 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0373 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0276 - acc: 0.9956\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0335 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0382 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0293 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0317 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0396 - acc: 0.9930\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 0.0277 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0289 - acc: 0.9956\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0486 - acc: 0.9924\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0298 - acc: 0.9954\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0312 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0319 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0387 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 13ms/sample - loss: 0.0320 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0290 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0383 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0320 - acc: 0.9954\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0334 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0365 - acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/sample - loss: 0.0393 - acc: 0.9932\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0413 - acc: 0.9927\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0285 - acc: 0.9956\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0295 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0325 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0277 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0287 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0330 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0267 - acc: 0.9956\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0359 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0293 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0265 - acc: 0.9957\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0336 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0325 - acc: 0.9954\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0311 - acc: 0.9954\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0432 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0390 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0498 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0445 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0435 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0408 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0389 - acc: 0.9940\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0382 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0416 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0394 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0425 - acc: 0.9936\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0423 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0367 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0392 - acc: 0.9943\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0378 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0375 - acc: 0.9933\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0507 - acc: 0.9920\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0370 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0406 - acc: 0.9924\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0403 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0654 - acc: 0.9877\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0355 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0451 - acc: 0.9934\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0417 - acc: 0.9944\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0357 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0329 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0292 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0361 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0325 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0369 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0305 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0325 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0358 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0355 - acc: 0.9945\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0314 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0310 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0358 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0337 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0279 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0336 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0325 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0308 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0310 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0226 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0306 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0285 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0350 - acc: 0.9943\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0337 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0350 - acc: 0.9940\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0352 - acc: 0.9939\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0351 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0315 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0342 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0297 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0331 - acc: 0.9943\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0280 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0310 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0292 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0282 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0693 - acc: 0.9905\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0306 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0299 - acc: 0.9942\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0416 - acc: 0.9936\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0341 - acc: 0.9941\n",
      "1/1 [==============================] - 0s 11ms/sample - loss: 0.0353 - acc: 0.9946\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0666 - acc: 0.9911\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0381 - acc: 0.9937\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0297 - acc: 0.9949\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0265 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0318 - acc: 0.9947\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0312 - acc: 0.9948\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0268 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0333 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0349 - acc: 0.9939\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0284 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 8ms/sample - loss: 0.0294 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0305 - acc: 0.9951\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0286 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0294 - acc: 0.9953\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0271 - acc: 0.9955\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0294 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0298 - acc: 0.9950\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0589 - acc: 0.9901\n",
      "1/1 [==============================] - 0s 10ms/sample - loss: 0.0246 - acc: 0.9952\n",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0427 - acc: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 9ms/sample - loss: 0.0268 - acc: 0.9953\n"
     ]
    }
   ],
   "source": [
    "for n in range(0, len(train_labels)):\n",
    "    train_images_n = np.reshape(train_images[n], newshape=(1,len(train_images[n]),len(train_images[n][0]),1))\n",
    "    train_labels_q = np.zeros((1,len(train_images[n]),len(train_images[n][0]),no_of_labels))\n",
    "    for i in range(0, len(train_labels[n])):\n",
    "        for j in range(0, len(train_labels[n][0])):\n",
    "            label = train_labels[0][i][j][0]\n",
    "            train_labels_q[0][i][j][int(label)] = 1\n",
    "    model.fit(train_images_n, train_labels_q, epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 11ms/sample - loss: 1.6604 - acc: 0.9937\n",
      "Test accuracy: 0.99370897\n"
     ]
    }
   ],
   "source": [
    "test_labels_q = np.zeros((len(test_images),len(test_images[0]),len(test_images[0][0]),no_of_labels))\n",
    "\n",
    "for n in range(0, len(test_labels)):\n",
    "    for i in range(0, len(test_labels[0])):\n",
    "        for j in range(0, len(test_labels[0][0])):\n",
    "            label = test_labels[n][i][j][0]\n",
    "            test_labels_q[n][i][j][int(label)] = 1\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels_q)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_images)\n",
    "prediction = np.reshape(prediction, newshape=(40,32,32,no_of_labels))\n",
    "prediction = prediction.argmax(axis=3)\n",
    "prediction = np.reshape(prediction, newshape=(40,32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./cifar-10-npy/test_labels_predictions', prediction)\n",
    "np.save('./cifar-10-npy/test_data_predictions', test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
